{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    temperature = 0.1,\n",
    "    groq_api_key = \"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\",\n",
    "    model_name = \"llama3-70b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the capital of India?\"\n",
    "result = llm.invoke(query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000211CA8DD6A0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000211CA8DE210>, model_name='llama3-70b-8192', temperature=0.1, model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"you are required to answer correctly for the question provided to you {question} \\\n",
    "    If you don't know or not able to understand the question then, you can say \"Not able to provide correct answer\".\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll do my best to provide a correct answer.\n",
      "\n",
      "In Chroma, a distributed database for storing and managing large amounts of time-series data, metadata refers to information about the data itself, such as table schema, column names, and data types.\n",
      "\n",
      "**Storing metadata as Persistent:**\n",
      "\n",
      "In Chroma, storing metadata as persistent means that the metadata is written to disk storage, typically in a separate metadata store or catalog. This approach has the following characteristics:\n",
      "\n",
      "**Advantages:**\n",
      "\n",
      "1. **Durability**: Metadata is persisted even in the event of a node failure or restart, ensuring that the database remains consistent and available.\n",
      "2. **Scalability**: Persistent metadata storage allows Chroma to scale horizontally, as new nodes can be added to the cluster without affecting metadata availability.\n",
      "\n",
      "**Shortcomings:**\n",
      "\n",
      "1. **Performance overhead**: Writing metadata to disk can introduce latency and overhead, potentially impacting query performance.\n",
      "2. **Additional storage requirements**: Storing metadata on disk requires additional storage capacity, which can increase costs and complexity.\n",
      "\n",
      "**Storing metadata in Memory (In-Memory):**\n",
      "\n",
      "In Chroma, storing metadata in memory means that the metadata is stored in RAM (Random Access Memory) instead of on disk. This approach has the following characteristics:\n",
      "\n",
      "**Advantages:**\n",
      "\n",
      "1. **Faster access**: In-memory metadata storage provides faster access to metadata, reducing query latency and improving overall performance.\n",
      "2. **Lower overhead**: In-memory storage eliminates the need for disk I/O, reducing the overhead associated with persistent storage.\n",
      "\n",
      "**Shortcomings:**\n",
      "\n",
      "1. **Volatility**: In-memory metadata is lost in the event of a node failure or restart, requiring metadata to be reconstructed or reloaded from disk.\n",
      "2. **Limited scalability**: In-memory metadata storage can become a bottleneck as the cluster grows, as each node must maintain a copy of the metadata in RAM.\n",
      "\n",
      "In summary, storing metadata as persistent provides durability and scalability but may introduce performance overhead and additional storage requirements. Storing metadata in memory offers faster access and lower overhead but is volatile and may limit scalability.\n",
      "\n",
      "Please let me know if this answer meets your expectations!\n"
     ]
    }
   ],
   "source": [
    "query = \"what is difference between storing the metadata as persistent and in memory in chroma db and what are the shortcomings for both?\"\n",
    "chain = prompt_template | llm\n",
    "result = chain.invoke(input = {\"question\": query})\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 2, 4, 2]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def reassignedPriorities(priorities):\n",
    "    # Step 1: Find all unique priorities\n",
    "    unique_priorities = sorted(set(priorities))\n",
    "    \n",
    "    # Step 2: Create a mapping from the original priority to the new priority\n",
    "    priority_map = {priority: index + 1 for index, priority in enumerate(unique_priorities)}\n",
    "    \n",
    "    # Step 3: Replace each priority with the new assigned priority\n",
    "    reassigned = [priority_map[priority] for priority in priorities]\n",
    "    \n",
    "    return reassigned\n",
    "\n",
    "priorities = [4,1,3,7,3]\n",
    "\n",
    "reassignedPriorities(priorities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the value of c is: 30\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 20\n",
    "c = a+b\n",
    "print(f\"the value of c is:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
